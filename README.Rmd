---
title: "Estimación mediante MMLE"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
pacman::p_load(tidyverse,mirt)
```


El objetivo de este documento es desarrollar una intuición acerca de la estimación de parámetros en un modelo IRT. La estimación de parámetros en este caso se hace bajo el método llamado, marginal maximim likelihood estimation. En base a la literatura, este es el método más común de estimación, y se basa en la idea de que la muestra de personas que se utiliza para la estimación de los parámetros de los ítems es circunstancial (no es el objeto de interés como tal), de modo tal que utiliza, además de las respuesta de los examinados, información a priori de la distribución del atributo latente. En general, se asume que este atributo se distribuye normalmente en la población. 


### Recordando el modelo:

$$ p(X_{ij}=1|\theta_i,\alpha_j,\delta_j) =\frac{1}{1+e^{-\alpha_j(\theta_{i} - \delta_j)}}$$


El modelo dice que la probabilidad de obtener una respuesta correcta es una función de una serie de parámetros. Respecto a los ítems, estos pueden estar caracterizados por 1, 2 o 3 parámetros (usualmente 2). En el caso de las personas, estas están caracterizadas por 1 parámetro, al cual se le suele llamar habilidad.


```{r}
curve(expr = 1/(1+exp(-1*(x-0))), from = -3,to = 3, ylab = "p(x = 1)", xlab="Habilidad")
```

¿Cómo se estiman los parámetros de los ítems y cómo se estiman los parámetros de las personas? 
En el método más común se estiman primero los parámetros de los ítems y luego los parámetros de las personas. Este método se llama Marginal Maximum Likelihood. 



## Pasos de la estimación:

1.- Estructura de la variable latente: se denite la estructura de la variable que caracteriza a las personas, en términos de ubicaciones y pesos (esto es lo que define a una distribución). En general, asumimos que la habilidad de distribuye normalmente y que va de -3 a 3. Debemos elegir puntos (nodos) en la distribución y su determinado peso (frecuencia o probabilidad de ocurrencia).


2.- Parámetros de los ítems. Tenemos que definir valores para los parámetros de los ítems, los cuales parten de valores a priori que se van modificando en pasos hasta que se llega un óptimo.

3- Necesitamos datos: la estimación se realiza en base a patrones de respuesta, los cuales permiten estimar los parámetros óptimos dado un conjunto de datos.


Proceso de estimación:


### Likelihood:

Necesitamos entender la idea de verosimilitud (y también lo que es la máxima verosimilitud) a nivel general (método general para la estimación de parámetros). La verosimilitud (likelihood) no es otra cosa que el resultado de estimar la probabilidad de ocurrencia de ciertos datos, dado un un modelo y un determinado valor en los parámetros del mismo.

$$ p(x|\theta,\alpha,\delta)$$
Por ejemplo, si tenemos un patrón de respuesta (1,1,0,0,0), y tenemos un vector $\delta$ = (-1,-.5,0,1,2) que caracteriza la dificultad de los ítems, y un vector $\alpha$ = (1,1,1.5,0.8,2) que caracteriza a la discriminación, entonces podemos estimar qué tan verosimil es el patrón de respuestas dado esta información, y adicionalmente, un valor a priori de theta (la habilidad), podríamos suponer un valor 1.


```{r}
likeli = function(x,dis,dif,thet){
  lik_val = c()
  for(i in 1:length(thet)){
  p = (1/(1+exp(-dis*(thet[i]-dif))))
  lik_val[i] = prod(p^x*(1-p)^(1-x))
  }
  return(lik_val)
}
```


```{r}
patron1= c(1,1,0,0,0)
dificultad1 = c(-1,-.5,0,1,2)
discriminacion1 = c(1,1,1.5,0.8,2)
theta1 = 1

likeli(x=patron1,dis = discriminacion1, dif = dificultad1, thet = theta1)
```

Podemos obtener un resultado que resuelve la función de indicamos anteriormente. Lo interesante es que, podemos iterar esta función dejando algunos parámetros constantes, para ver cuál es el parámetro más verosimil que es de nuestro interés. Por ejemplo, podríamos buscar el valor más verosimil para la habilidad de un evaluado con el patrón anterior, dado que asumimos que los parámetros de los ítems son valores conocidos.


```{r}
patron1= c(1,1,0,0,0)
dificultad1 = c(-1,-.5,0,1,2)
discriminacion1 = c(1,1,1.5,0.8,2)
theta1 = seq(-3,3,0.2)

likeli1 = likeli(x=patron1,dis = discriminacion1, dif = dificultad1, thet = theta1)

plot(theta1, likeli1)
```

Obtenemos que podemos ver que hay valores de habilidad más verosímiles que otros, y que de hecho hay un máximo. Esa es la esencia de la estimación por máxima verosimilitud, encontrar el valor más verosimil dado un conjunto de datos y un modelo para uno o más parámetros. Esto permite que el proceso de estimación sea un proceso de optimización. En la práctica, la función que se optimiza se basa en la suma del logaritmo, y no en el producto, de las probabilidades independientemente estimadas. Esto porque la multiplicación de probabilidades lleva a valores pequeños que computacionalmente son intratables.


```{r}
loglikeli = function(x,dis,dif,thet){
  loglik_val = c()
  for(i in 1:length(thet)){
  p = (1/(1+exp(-dis*(thet[i]-dif))))
  loglik_val[i] = sum(log(p^x*(1-p)^(1-x)))
  }
  return(loglik_val)
}
```


```{r}
patron1= c(1,1,0,0,0)
dificultad1 = c(-1,-.5,0,1,2)
discriminacion1 = c(1,1,1.5,0.8,2)
theta1 = seq(-3,3,0.1)

loglikeli1 = loglikeli(x=patron1,dis = discriminacion1, dif = dificultad1, thet = theta1)

plot(theta1, loglikeli1)
```


El máximo verosimil es el mismo en ambos casos. Sí es posible notar un hecho importante, que es que la función tiene una forma, la cual puede ser más o menos chata. Por ejemplo, vemos que si bien hay un máximo, este punto no es tan sobresaliente respecto a otros puntos próximos. ¿Qué pasa si aumentamos el número de ítems?



```{r}
patron2= sample(c(0,1),100,replace = T)
dificultad2 = rnorm(100,0,1)
discriminacion2 = c(runif(100,0.8,2))
theta2 = seq(-3,3,0.1)

loglikeli2 = loglikeli(x=patron2,dis = discriminacion2, dif = dificultad2, thet = theta2)

plot(theta2, loglikeli2)
```

Hay un pequeño cambio en el la forma de la función, que se traduce en una mayor certeza respecto a cuál es el valor más verosimil a los datos. 


La estimación de los parámetros de los ítems tiene características similares, pero utiliza otros elementos. Los que se ven a continuación:


## Concepto de Marginal Maximum Likelihood:


Se basa en un modelo bayesiano, de modo que se parte con una idea respecto a los posibles valores de los parámetros (en este caso de habilidad), y de los pesos asociados a estos. El Teorema de Byes es:

$$ P(\theta|\textbf{x}) = \frac{P(\textbf{x}|\theta)P(\theta )}{P(\textbf{x})}$$

En este caso, no nos interesa el resultado del Teorema, pero sí algunas de las características. Principalmente la posibilidad de calcular p(x), esto es la probabilidad de observar un cierto patrón de respuestas

En concreto, la estimación por marginal maximum likelihood, viene dada por la posibilidad de calcular la probabilidad marginal del patrón de respuestas, a partir de la descomposición marginal condicional. Esto es, la probabilidad marginal de un fenómeno es igual a la suma de las 
probabilidades condicionales del mismo, bajo condiciones exhaustivas. 


Dos características de la estimación: distribución a priori de la variable latente (habilidad) y dicretización de la misma. Para este ejemplo utilizaremos una discretización en 10 puntos de una distribución normal.

```{r}
Xr = seq(-4,4, length.out = 10) ## Xr (valores de teta, de la cuadratura)
AXr = c(.00012, .00281, .03002, .14580, .32130, .32130, .14580, .03002, .00281, .00012) ## Pesos 
bet = c(0,0,0,0,0) # Dificultad
dis = c(1,1,1,1,1) # discriminación
```

En el siguiente gráfico se muestran 10 puntos (nodos), y sus pesos (alturas) que definen la distribución a priori de la habilidad.

```{r}
plot(Xr,AXr)
```


Esta información la utilizaremos en conjunto con los datos para hacer una estimación preliminar de los parámetros de los ítems, y generar una intuición de cómo estos son estimados. 

Vamos a suponer que todos los ítems tienen los mismos parámetros al iniciar la estimación, y supondremos que solo están definidos por la dificultad y la discriminación. 


El elemento base es la probabilidad marginal de un patrón, el cual se calcula multiplicando la likelihood por el valor del ponderador del valor del nodo. La sumatoria de esos valores permite el cálculo de la probabilidad marginal del patrón.



```{r}
pat = c(1,0,1,0,1)
b = c(0,0,0,0,0)
a = c(1,1,1,1,1)
Xr = seq(-4,4, length.out = 10) ## Xr (valores de teta, de la cuadratura)
AXr = c(.00012, .00281, .03002, .14580, .32130, .32130, .14580, .03002, .00281, .00012) ## Pesos 

### Paso 1: Calcular L(Xr) para un patrón en un nodo:

LXr = c()

for(i in 1:10){
pj = exp(a*(Xr[i] - b))/(1 + exp(a*(Xr[i]-b))) ## Probabilidad de respuesta correcta o incorrecta de cada ítem. 
LXr[i] = prod((pj^pat)*(1-pj)^(1-pat)) # multiplicamos las probabilidades individuales de respuesta (cada ítem) y guardamos el valor. Luego cambiamos theta
}

plot(Xr,LXr) ## Estos son los likelihoods, condicional a Xr (aunque técnicamente es lo mismo que theta)

LXr ## Primer elemento listo. Likelihoods del patrón condicional a theta (Xr) y parámetros

PL = LXr*AXr ## Este elemento es nuevo. El likelihood de cada Xr multiplicado por AXr. Estamos calculando la probabilidad marginal del patrón. 

PL ## Esto vendría a ser algo así como el likelihood ponderando por un peso a priori. La suma de esto (recordemos la integral) da la probabilidad marginal del patrón

PL_suma = sum(PL) ## Al sumar, estoy reuniendo toda la información. Teníamos distintos thetas, ahora es una sola cosa. 
PL_suma ## Esto es la probabilidad marginal para un patrón que sería (1,0,1,0,1). ¿Qué pasaría con otro patrón?
```

Cuando tenemos datos empíricos, tenemos un conjunto de patrones. Lo importante es saber cuántas veces se repite un patrón. Esto lo podemos averiguar fácilmente

```{r}
set.seed(1234)
items1 = simdata(a = matrix(c(1,1.3,1.3,0.8,1.5)), d=matrix(c(2,1,0,-1,-2)), N=500, itemtype = "2PL")
```


```{r}
patron = data.frame(items1) %>% unite(col="patron",sep = "") %>% pull()
items1 = data.frame(cbind(items1,patron))
resumen = items1 %>% count(patron)
items1 = items1 %>% left_join(resumen)
items1 = unique(items1)
```

```{r}
head(items1)
```

Lo que tenemos que hacer es:

1.- Calcular la likelihood para cada patrón para cada nodo.

2.- Calcular la probabilidad marginal de cada patrón (sumatoria de la likelihood ponderada por el peso del nodo).

3.- Calcular la probabilidad posterior $p(\theta|x)$


Paso 1:

```{r}
b = c(0,0,0,0,0)
a = c(1,1,1,1,1)
items1 = items1 %>% mutate(across(.cols = 1:5, .fns = function(x){as.numeric(x)}))
lik_matriz = c()
for(i in 1:nrow(items1)){
  liks = likeli(x=items1[i,1:5],dif = b, dis = a,thet = Xr)
  lik_matriz = rbind(lik_matriz,liks)
}
```

Paso 2:

```{r}
colnames(lik_matriz) = paste("Xr",round(Xr,2), sep = "_")
lik_data = data.frame(lik_matriz) ## Base de datos con toda la información (LXr) para cada valor theta
lik_data
marg_prob = lik_matriz %*% AXr ## calculamos las probabilidades marginales de cada patrón 
marg_prob ## Ahora se guarda para cada patrón un PL que sería algo así como un resumen de un montón de cosas sum(likelihood*AXr), moviéndonos en Xr (theta) para cada patrón (probabilidad marginal)
```


Paso 3: la probabilidad posterior, de un valor específico de theta (definido a priori) dado un patrón (fijo), y un peso del nodo (AXr) es:


```{r}
lik_matriz[1,5] ## valor puntual de la likelihood
Xr[5] ## valor del nodo
AXr[5] ## valor del peso a priori
marg_prob[5] # probabilidad marginal del patrón
items1[5,6] # patrón
lik_matriz[1,5]*AXr[5]/marg_prob[5]
```

Para cada nodo podemos calcular todas las probabilidades condicionales variando los patrones observados.


```{r}
lik_matriz[,5]*AXr[5]/marg_prob
```

Estas son probabilidades posteriores. Lo que podemos hacer ahora es ponderar el número de casos que obtuvo un determinado patrón por este valor y sumarlos, y hacer esto para cada nodo. En contreto, esto es una suma ponderada (el ponderador es la probabilidad posterior):

```{r}
lik_matriz[,5]*AXr[5]*items1$n/marg_prob
```

Estos valores indican cuanta gente se espera que tenga un valor de habilidad, dada la probabilidad posterior del valor específico de habilidad. La suma indica cuanta gente de la muestra se espera que tenga un cierto valor de habilidad.

```{r}
sum(lik_matriz[,5]*AXr[5]*items1$n/marg_prob)
```

En este caso 167 personas se espera que tengan el valor 167. Ahora, podemos calcular esto para todos los nodos.

```{r}
nrj = c()
for(i in 1:10){
nrj[i] = sum(lik_matriz[,i]*AXr[i]*items1$n/marg_prob)
}
nrj
```

Hay valores de Xr que en sí son poco probables (probabilidad posterior) y suponemos por tanto que son pocas las personas de la muestra que se ubican en esa determinada posición.

Podemos, ahora, hacer otro cálculo, que es estimar la cantidad esperada de personas que tengan correctamente respondido un determinado ítem, al solo sumar los casos de personas que tienen el ítem contestado de forma correcta. Veamos el caso del ítem 1:


```{r}
items1$Item_1
```

La cantidad de personas que se espera que tengan correctamente respondido el ítem 1 para cada nodo es:


```{r}
crj = c()
for(i in 1:10){
crj[i] = sum(items1$Item_1*lik_matriz[,i]*AXr[i]*items1$n/marg_prob)
}
```


```{r}
options(scipen = 999)
cbind(Xr,crj,nrj)
```

Hay un hecho interesante, que es que la cantidad de casos esperado que tenga un ítem correcto crj, tiende a nrj en la medida en que Xr es más alto, ¿por qué pasa esto?
Hay que centrarse en aquello en lo cual difiere la estimación del número de personas que se espera tengan un determinado ítem correcto. No difieren en los ponderadores (son simétricos), y levemente en el posterior.

```{r}
cbind(items1$Item_1,lik_matriz[,2],lik_matriz[,9],items1$patron)
```



```{r}
pj_it1 = (1/(1+exp(-a[1]*(Xr-b[1]))))
-sum(crj - nrj*pj_it1)
```

